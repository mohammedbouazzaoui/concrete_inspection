{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspection of concrete structures\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all libraries needed for this notebook\n",
    "###############################################\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import autokeras as ak\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create an X and Y_cat for modelling\n",
    "######################################\n",
    "#\n",
    "\n",
    "# Get the list of all imagefiles with their subdirectory\n",
    "mergeinfo=[]\n",
    "for i in ['CX', 'UX']:\n",
    "    path = \"../../../concrete_inspection_dataset/SDNET2018/X\" + \"/\"+i\n",
    "    dir_list = os.listdir(path)\n",
    "    stop=1000\n",
    "    for j in dir_list:\n",
    "        full=path + \"/\" + j\n",
    "        if i == 'CX':\n",
    "            CRACK=[1,0]  # cracked\n",
    "        else:\n",
    "            CRACK=[0,1]  # not cracked\n",
    "\n",
    "        mergeinfo.append([CRACK,full])\n",
    "        if stop == 0:\n",
    "            break\n",
    "        else:\n",
    "            stop-=1\n",
    " \n",
    "    \n",
    "dfinfo=pd.DataFrame(mergeinfo, columns=['label','path'])\n",
    "\n",
    "#print(dfinfo.head())\n",
    "#Use the path to read images.\n",
    "SIZE=64\n",
    "dfinfo['image'] = dfinfo['path'].map(lambda x: np.asarray(Image.open(x).resize((SIZE,SIZE))))\n",
    "#Convert dataframe column of images into numpy array\n",
    "X = np.asarray(dfinfo['image'].tolist())\n",
    "\n",
    "X = X/255. # Scale values\n",
    "Y=np.array(list(dfinfo['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinfo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_auto.shape, y_train_auto.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let autokeras select a model\n",
    "#\n",
    "# testing/validating select of model\n",
    "##################################################################################\n",
    "#\n",
    "# start model selection\n",
    "#\n",
    "XXmain, XXauto, YYmain, YYauto = train_test_split(X, Y, test_size=0.10, random_state=42, shuffle=True)\n",
    "x_train_auto, x_test_auto, y_train_auto, y_test_auto = train_test_split(XXauto, YYauto, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "#\n",
    "# start model selection\n",
    "# Define classifier for autokeras. Check different models\n",
    "# \n",
    "#clf = ak.ImageClassifier(num_classes=None, max_trials=5) #MaxTrials - max. number of keras models to try\n",
    "clf = ak.ImageClassifier(\n",
    "    num_classes=None,\n",
    "    multi_label=True,\n",
    "    loss=None,\n",
    "    metrics=None,\n",
    "    project_name=\"image_classifier\",\n",
    "    max_trials=25,\n",
    "    directory=None,\n",
    "    objective=\"accuracy\",\n",
    "    tuner=None,\n",
    "    overwrite=False,\n",
    "    seed=None,\n",
    "    max_model_size=None\n",
    ")\n",
    "\n",
    "clf.fit(x_train_auto, y_train_auto, epochs=3)\n",
    "\n",
    "#Evaluate the classifier on test data\n",
    "\n",
    "_, acc = clf.evaluate(x_test_auto, y_test_auto)\n",
    "print(\"Accuracy = \", (acc * 100.0), \"%\")\n",
    "\n",
    "# get the final best performing model\n",
    "model = clf.export_model()\n",
    "\n",
    "#Save the best model \n",
    "model.save('../pybin/models/activemodel_auto_besttotrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XXmain.shape, XXauto.shape, YYmain.shape, YYauto.shape\n",
    "x_train_auto.shape, x_test_auto.shape, y_train_auto.shape, y_test_auto.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the best model\n",
    "######################\n",
    "#\n",
    "\n",
    "# Split the data in train/test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(XXmain, YYmain, test_size=0.30, random_state=42, shuffle=True)\n",
    "\n",
    "# Load the model to train\n",
    "model = keras.models.load_model('../pybin/models/activemodel_auto_besttotrain')\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
    "                       tf.keras.metrics.FalseNegatives()])\n",
    "# Train\n",
    "history = model.fit(X_train,y_train,epochs=10)\n",
    "\n",
    "# Test\n",
    "res=model.evaluate(X_test,y_test)\n",
    "\n",
    "# Save the model\n",
    "model.save('../pybin/models/activemodel_autokeras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import tensorflow\n",
    "\n",
    "def plot_history(history : tensorflow.keras.callbacks.History):\n",
    "    \"\"\" This helper function takes the tensorflow.python.keras.callbacks.History\n",
    "    that is output from your `fit` method to plot the loss and accuracy of\n",
    "    the training and validation set.\n",
    "    \"\"\"\n",
    " \n",
    "    fig, axs = plt.subplots(1,3, figsize=(22,6))\n",
    "    axs[0].plot(history.history['binary_accuracy'], label='training')\n",
    "    axs[0].set(xlabel = 'Epoch', ylabel='Binary accuracy', ylim=[0, 1])\n",
    "    axs[0].legend(loc='lower right')\n",
    "\n",
    "    axs[1].plot(history.history['loss'], label='training')\n",
    "    \n",
    "    axs[1].set(xlabel = 'Epoch', ylabel='Loss', ylim=[0, 1])\n",
    "    axs[1].legend(loc='lower right')\n",
    "\n",
    "    axs[2].plot(history.history['false_negatives_1'], label = 'training')\n",
    " \n",
    "    axs[2].set(xlabel = 'Epoch', ylabel='false_negatives', ylim=[0, 500])\n",
    "    axs[2].legend(loc='lower right')\n",
    "\n",
    "    \n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a testprediction\n",
    "###################\n",
    "#\n",
    "model = keras.models.load_model('../pybin/models/activemodel_best_trained9999')\n",
    "\n",
    "# If importing an external image you'll have to rescale it (so : divide by 225.)\n",
    "#The augmented data in X_test_augm is are already rescaled!\n",
    "img=np.reshape(X_test[10], (-1, SIZE, SIZE, 3)) \n",
    "#\n",
    "y_pred=model.predict(img)\n",
    "# print result\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "STOP=0\n",
    "SIZE=256\n",
    "for pic in dfinfo['path']:\n",
    "    img = np.asarray(Image.open(pic).resize((SIZE,SIZE)))\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.imshow(img)\n",
    "    #Convert dataframe column of images into numpy array\n",
    "    X = np.asarray(img.tolist())\n",
    "    X = X/255. # Scale values\n",
    "    Ximg=np.reshape(X, (-1, SIZE, SIZE, 3)) \n",
    "    #\n",
    "    result=model.predict(Ximg)\n",
    "    # print result\n",
    "    print(result)\n",
    "    if STOP == 10:\n",
    "        break\n",
    "    else:\n",
    "        STOP+=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43555e2ca980a29bec6bc428ca6c1f56020b40b98b62f58def2ce1400820b105"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
